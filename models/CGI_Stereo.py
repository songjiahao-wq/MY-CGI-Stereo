"""
CGI-Stereo: Context and Geometry Interaction Stereo Matching Network
åŸºäºä¸Šä¸‹æ–‡ä¸å‡ ä½•äº¤äº’çš„ç«‹ä½“åŒ¹é…ç½‘ç»œ

è¯¥ç½‘ç»œå®ç°äº†ä¸€ç§åˆ›æ–°çš„ç«‹ä½“è§†è§‰æ·±åº¦ä¼°è®¡ç®—æ³•ï¼Œé€šè¿‡ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶å®ç°é«˜ç²¾åº¦è§†å·®ä¼°è®¡ï¼š
1. ç‰¹å¾æå–ï¼šåŸºäº MobileNetV2 çš„å¤šå°ºåº¦ç‰¹å¾æå–å™¨
2. ç‰¹å¾ä¸Šé‡‡æ ·ï¼šé€šè¿‡åå·ç§¯å®ç°å¤šå°ºåº¦ç‰¹å¾èåˆ
3. ä¸Šä¸‹æ–‡å‡ ä½•èåˆï¼šå°†è¯­ä¹‰ç‰¹å¾ä¸å‡ ä½•ä»£ä»·ä½“è¿›è¡Œäº¤äº’èåˆ
4. æ²™æ¼ç½‘ç»œï¼šé€šè¿‡å¤šå°ºåº¦ç¼–è§£ç ç»“æ„ä¼˜åŒ–ä»£ä»·ä½“
5. ç©ºé—´é‡‘å­—å¡”ï¼šå®ç°äºšåƒç´ çº§è§†å·®ç»†åŒ–

è®ºæ–‡æ ¸å¿ƒæ€æƒ³ï¼šé€šè¿‡ Context-Geometry Fusion (CGF) æ¨¡å—ï¼Œå°†å›¾åƒçš„è¯­ä¹‰ä¸Šä¸‹æ–‡ä¿¡æ¯
ä¸ç«‹ä½“åŒ¹é…çš„å‡ ä½•çº¦æŸä¿¡æ¯æœ‰æ•ˆèåˆï¼Œæå‡è§†å·®ä¼°è®¡çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚
"""

from __future__ import print_function
import torch
import torch.nn as nn
import torch.utils.data
from torch.autograd import Variable
import torch.nn.functional as F
from models.submodule import *  # åŒ…å« BasicConv, Conv2x, build_norm_correlation_volume ç­‰è‡ªå®šä¹‰æ¨¡å—
import math
import gc
import time
import timm  # PyTorch Image Models (TIMM) åº“ï¼Œç”¨äºé¢„è®­ç»ƒæ¨¡å‹

class SubModule(nn.Module):
    """
    åŸºç¡€æ¨¡å—ç±»ï¼Œæä¾›æƒé‡åˆå§‹åŒ–åŠŸèƒ½
    """
    def __init__(self):
        super(SubModule, self).__init__()

    def weight_init(self):
        """
        æƒé‡åˆå§‹åŒ–æ–¹æ³•ï¼Œä½¿ç”¨ He åˆå§‹åŒ–
        å¯¹äºå·ç§¯å±‚ï¼šä½¿ç”¨æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œstd = sqrt(2/n)
        å¯¹äºæ‰¹å½’ä¸€åŒ–å±‚ï¼šæƒé‡åˆå§‹åŒ–ä¸º1ï¼Œåç½®åˆå§‹åŒ–ä¸º0
        """
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.Conv3d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.kernel_size[2] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm3d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()


class Feature(SubModule):
    """
    ç‰¹å¾æå–ç½‘ç»œï¼ŒåŸºäº MobileNetV2 çš„å¤šå°ºåº¦ç‰¹å¾æå–å™¨

    ä½¿ç”¨é¢„è®­ç»ƒçš„ MobileNetV2_100 ä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œæå–4ä¸ªä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾ï¼š
    - x4: 1/4åˆ†è¾¨ç‡ç‰¹å¾ï¼Œé€šé“æ•°24ï¼ŒåŒ…å«ä¸­ç­‰å°ºåº¦ä¿¡æ¯
    - x8: 1/8åˆ†è¾¨ç‡ç‰¹å¾ï¼Œé€šé“æ•°32ï¼ŒåŒ…å«è¾ƒç²—å°ºåº¦ä¿¡æ¯
    - x16: 1/16åˆ†è¾¨ç‡ç‰¹å¾ï¼Œé€šé“æ•°96ï¼ŒåŒ…å«ç²—å°ºåº¦ä¿¡æ¯
    - x32: 1/32åˆ†è¾¨ç‡ç‰¹å¾ï¼Œé€šé“æ•°160ï¼ŒåŒ…å«æœ€ç²—å°ºåº¦çš„è¯­ä¹‰ä¿¡æ¯

    é€‰æ‹© MobileNetV2 çš„åŸå› ï¼šè½»é‡çº§ã€è®¡ç®—æ•ˆç‡é«˜ã€ç‰¹å¾è¡¨è¾¾èƒ½åŠ›å¼º
    """
    def __init__(self):
        super(Feature, self).__init__()
        pretrained = True
        self.features_only = True
        # ä½¿ç”¨ timm åº“åˆ›å»ºé¢„è®­ç»ƒçš„ MobileNetV2ï¼Œfeatures_only=True åªè¿”å›ç‰¹å¾å›¾
        self.model = timm.create_model('mobilenetv2_100', pretrained=pretrained, features_only=self.features_only)
        # self.model = timm.create_model('mobilenetv3_small_100', pretrained=pretrained, features_only=self.features_only)

        # é€‰æ‹©çš„ MobileNetV2 å±‚ç´¢å¼•ï¼š[1,2,3,5,6]
        # å¯¹åº”çš„è¾“å‡ºé€šé“æ•°ï¼š[16, 24, 32, 96, 160]
        layers = [1,2,3,5,6]
        chans = [16, 24, 32, 96, 160]
        # å¤åˆ¶ MobileNetV2 çš„åŸºç¡€ç»“æ„
        self.conv_stem = self.model.conv_stem
        self.bn1 = self.model.bn1
        if hasattr(self.model, 'act1'):
            self.act1 = self.model.act1
        # self.act1 = self.model.act1

        # æ„å»ºä¸åŒæ·±åº¦çš„æ¨¡å—å—
        self.block0 = torch.nn.Sequential(*self.model.blocks[0:layers[0]])  # è¾“å‡º16é€šé“
        self.block1 = torch.nn.Sequential(*self.model.blocks[layers[0]:layers[1]])  # è¾“å‡º24é€šé“
        self.block2 = torch.nn.Sequential(*self.model.blocks[layers[1]:layers[2]])  # è¾“å‡º32é€šé“
        self.block3 = torch.nn.Sequential(*self.model.blocks[layers[2]:layers[3]])  # è¾“å‡º96é€šé“
        self.block4 = torch.nn.Sequential(*self.model.blocks[layers[3]:layers[4]])  # è¾“å‡º160é€šé“
        'åœ¨ç«‹ä½“åŒ¹é…ï¼ˆStereoï¼‰æˆ–æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬ä¸€èˆ¬åªå–åˆ° block5 è¾“å‡ºï¼ˆ160é€šé“ï¼‰ä¸ºæœ€é«˜å±‚ç‰¹å¾ï¼Œ'
        # æ³¨ï¼šè¿™é‡Œçš„ deconv32_16 åœ¨å½“å‰ç±»ä¸­æœªä½¿ç”¨ï¼Œå¯èƒ½æ˜¯è®¾è®¡é—ç•™
        self.deconv32_16 = Conv2x(chans[4], chans[3], deconv=True, concat=True)

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­ï¼Œæå–å¤šå°ºåº¦ç‰¹å¾

        Args:
            x: è¾“å…¥å›¾åƒå¼ é‡ [B, 3, H, W]

        Returns:
            List: åŒ…å«4ä¸ªå°ºåº¦ç‰¹å¾å›¾çš„åˆ—è¡¨ [x4, x8, x16, x32]
        """
        # if self.features_only:
        #     # å¦‚æœåªéœ€è¦ç‰¹å¾å›¾ï¼Œç›´æ¥è°ƒç”¨æ¨¡å‹
        # features = self.model(x)[:4]
        #     return [features[0], features[1], features[2], features[3]]
        # ç¬¬ä¸€é˜¶æ®µï¼šåˆå§‹å·ç§¯å¤„ç†
        if hasattr(self, 'act1'):
            x1 = self.act1(self.bn1(self.conv_stem(x)))
        else:
            x1 = self.bn1(self.conv_stem(x))  # [B, 32, H/2, W/2]

        # ç¬¬äºŒé˜¶æ®µï¼šé€šè¿‡ä¸åŒæ·±åº¦çš„æ¨¡å—æå–å¤šå°ºåº¦ç‰¹å¾
        x2 = self.block0(x1)   # [B, 16, H/2, W/2] - æ³¨æ„ï¼šè¿™é‡Œè¾“å‡ºæ˜¯16é€šé“
        x4 = self.block1(x2)  # [B, 24, H/4, W/4] - 1/4åˆ†è¾¨ç‡
        x8 = self.block2(x4)  # [B, 32, H/8, W/8]  - 1/8åˆ†è¾¨ç‡
        x16 = self.block3(x8) # [B, 96, H/16, W/16] - 1/16åˆ†è¾¨ç‡
        x32 = self.block4(x16)# [B, 160, H/32, W/32] - 1/32åˆ†è¾¨ç‡

        return [x4, x8, x16, x32]

class FeatUp(SubModule):
    """
    ç‰¹å¾ä¸Šé‡‡æ ·æ¨¡å—ï¼Œå®ç°å¤šå°ºåº¦ç‰¹å¾èåˆ

    é€šè¿‡è‡ªé¡¶å‘ä¸‹çš„è·¯å¾„ï¼Œå°†æ·±å±‚è¯­ä¹‰ç‰¹å¾ä¸æµ…å±‚ç»†èŠ‚ç‰¹å¾è¿›è¡Œèåˆï¼š
    1. x32(1/32) -> x16(1/16): ä½¿ç”¨åå·ç§¯ä¸Šé‡‡æ ·å¹¶ä¸x16ç‰¹å¾æ‹¼æ¥
    2. x16 -> x8(1/8): ç»§ç»­ä¸Šé‡‡æ ·å¹¶ä¸x8ç‰¹å¾æ‹¼æ¥
    3. x8 -> x4(1/4): æœ€ç»ˆä¸Šé‡‡æ ·å¹¶ä¸x4ç‰¹å¾æ‹¼æ¥

    è¿™ç§è®¾è®¡å……åˆ†åˆ©ç”¨äº†æ·±å±‚ç‰¹å¾çš„è¯­ä¹‰ä¿¡æ¯å’Œæµ…å±‚ç‰¹å¾çš„ç»†èŠ‚ä¿¡æ¯ï¼Œ
    ä¸ºåç»­çš„ç«‹ä½“åŒ¹é…æä¾›äº†æ›´åŠ ä¸°å¯Œçš„ç‰¹å¾è¡¨ç¤ºã€‚
    """
    def __init__(self):
        super(FeatUp, self).__init__()
        # ç‰¹å¾é€šé“é…ç½® [16, 24, 32, 96, 160] å¯¹åº”ä¸åŒå°ºåº¦
        chans = [16, 24, 32, 96, 160]

        # ä¸Šé‡‡æ ·è·¯å¾„ï¼šä»æ·±å±‚åˆ°æµ…å±‚çš„åå·ç§¯å±‚
        # Conv2x: åå·ç§¯+æ‹¼æ¥æ“ä½œï¼Œdeconv=Trueè¡¨ç¤ºä½¿ç”¨è½¬ç½®å·ç§¯ï¼Œconcat=Trueè¡¨ç¤ºä¸å¯¹åº”å±‚ç‰¹å¾æ‹¼æ¥
        self.deconv32_16 = Conv2x(chans[4], chans[3], deconv=True, concat=True)  # 160->96
        self.deconv16_8 = Conv2x(chans[3]*2, chans[2], deconv=True, concat=True)  # 96*2->32 (æ‹¼æ¥åé€šé“ç¿»å€)
        self.deconv8_4 = Conv2x(chans[2]*2, chans[1], deconv=True, concat=True)   # 32*2->24

        # æœ€ç»ˆèåˆå±‚ï¼šå¯¹1/4åˆ†è¾¨ç‡çš„ç‰¹å¾è¿›è¡Œè¿›ä¸€æ­¥å¤„ç†
        self.conv4 = BasicConv(chans[1]*2, chans[1]*2, kernel_size=3, stride=1, padding=1)  # 24*2->48

        self.weight_init()

    def forward(self, featL, featR=None):
        """
        å‰å‘ä¼ æ’­ï¼Œå®ç°å·¦å³å›¾åƒç‰¹å¾çš„ä¸Šé‡‡æ ·èåˆ

        Args:
            featL: å·¦å›¾åƒç‰¹å¾åˆ—è¡¨ [x4, x8, x16, x32]
            featR: å³å›¾åƒç‰¹å¾åˆ—è¡¨ [y4, y8, y16, y32]

        Returns:
            Tuple: (èåˆåçš„å·¦ç‰¹å¾, èåˆåçš„å³ç‰¹å¾)
                  æ¯ä¸ªéƒ½æ˜¯4å±‚ç‰¹å¾çš„åˆ—è¡¨ [x4', x8', x16', x32']
        """
        # è§£åŒ…å¤šå°ºåº¦ç‰¹å¾
        x4, x8, x16, x32 = featL  # å·¦å›¾åƒç‰¹å¾
        y4, y8, y16, y32 = featR  # å³å›¾åƒç‰¹å¾

        # ç¬¬ä¸€çº§ä¸Šé‡‡æ ·ï¼š1/32 -> 1/16
        # å°†é«˜å±‚æ¬¡çš„è¯­ä¹‰ç‰¹å¾ä¸Šé‡‡æ ·å¹¶ä¸ä¸­ç­‰å±‚æ¬¡ç‰¹å¾èåˆ
        x16 = self.deconv32_16(x32, x16)  # è¾“å…¥: (160, 96) -> è¾“å‡º: 96*2é€šé“
        y16 = self.deconv32_16(y32, y16)

        # ç¬¬äºŒçº§ä¸Šé‡‡æ ·ï¼š1/16 -> 1/8
        # ç»§ç»­èåˆæ›´ç»†è‡´çš„ç‰¹å¾ä¿¡æ¯
        x8 = self.deconv16_8(x16, x8)  # è¾“å…¥: (96*2, 32) -> è¾“å‡º: 32*2é€šé“
        y8 = self.deconv16_8(y16, y8)

        # ç¬¬ä¸‰çº§ä¸Šé‡‡æ ·ï¼š1/8 -> 1/4
        # è·å¾—æœ€é«˜åˆ†è¾¨ç‡çš„èåˆç‰¹å¾
        x4 = self.deconv8_4(x8, x4)    # è¾“å…¥: (32*2, 24) -> è¾“å‡º: 24*2é€šé“
        y4 = self.deconv8_4(y8, y4)

        # å¯¹1/4åˆ†è¾¨ç‡ç‰¹å¾è¿›è¡Œæœ€ç»ˆå¤„ç†
        x4 = self.conv4(x4)  # è¿›ä¸€æ­¥æå–1/4åˆ†è¾¨ç‡çš„ç‰¹å¾
        y4 = self.conv4(y4)

        return [x4, x8, x16, x32], [y4, y8, y16, y32]


class Context_Geometry_Fusion(SubModule):
    """
    ä¸Šä¸‹æ–‡å‡ ä½•èåˆæ¨¡å— (CGF) - CGI-Stereo çš„æ ¸å¿ƒåˆ›æ–°ç»„ä»¶

    è¯¥æ¨¡å—å®ç°äº†å›¾åƒè¯­ä¹‰ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸ç«‹ä½“å‡ ä½•çº¦æŸä¿¡æ¯çš„æœ‰æ•ˆèåˆï¼š
    1. è¯­ä¹‰ç‰¹å¾æå–ï¼šå°†2Då›¾åƒç‰¹å¾è½¬æ¢ä¸ºé€‚åˆä¸3Dä»£ä»·ä½“èåˆçš„è¡¨ç¤º
    2. æ³¨æ„åŠ›æœºåˆ¶ï¼šé€šè¿‡3Då·ç§¯è®¡ç®—æ³¨æ„åŠ›æƒé‡ï¼Œå¢å¼ºç›¸å…³åŒºåŸŸçš„å“åº”
    3. ç‰¹å¾èåˆï¼šä½¿ç”¨é—¨æ§æœºåˆ¶å°†è¯­ä¹‰ç‰¹å¾æ³¨å…¥åˆ°å‡ ä½•ä»£ä»·ä½“ä¸­
    4. ä¸Šä¸‹æ–‡èšåˆï¼šé€šè¿‡3Då·ç§¯è¿›ä¸€æ­¥èšåˆèåˆåçš„ç‰¹å¾

    è¿™ç§è®¾è®¡è®©ç½‘ç»œèƒ½å¤Ÿåˆ©ç”¨å›¾åƒçš„è¯­ä¹‰ä¿¡æ¯æ¥æŒ‡å¯¼ç«‹ä½“åŒ¹é…ï¼Œ
    ç‰¹åˆ«æ˜¯åœ¨çº¹ç†ç¼ºå¤±ã€é®æŒ¡ç­‰å›°éš¾åŒºåŸŸæå‡åŒ¹é…è´¨é‡ã€‚
    """
    def __init__(self, cv_chan, im_chan):
        """
        åˆå§‹åŒ–ä¸Šä¸‹æ–‡å‡ ä½•èåˆæ¨¡å—

        Args:
            cv_chan: ä»£ä»·ä½“é€šé“æ•° (cost volume channels)
            im_chan: å›¾åƒç‰¹å¾é€šé“æ•° (image feature channels)
        """
        super(Context_Geometry_Fusion, self).__init__()

        # è¯­ä¹‰ç‰¹å¾æå–ç½‘ç»œï¼šå°†2Då›¾åƒç‰¹å¾æŠ•å½±åˆ°ä»£ä»·ä½“ç©ºé—´
        self.semantic = nn.Sequential(
            # é¦–å…ˆå‡å°‘é€šé“æ•°ï¼Œé™ä½è®¡ç®—å¤æ‚åº¦
            BasicConv(im_chan, im_chan//2, kernel_size=1, stride=1, padding=0),
            # å°†ç‰¹å¾ç»´åº¦æ˜ å°„åˆ°ä»£ä»·ä½“é€šé“æ•°
            nn.Conv2d(im_chan//2, cv_chan, 1)
        )

        # æ³¨æ„åŠ›è®¡ç®—ç½‘ç»œï¼šç”Ÿæˆèåˆæƒé‡
        # ä½¿ç”¨3Då·ç§¯å¤„ç†ä»£ä»·ä½“ä¸è¯­ä¹‰ç‰¹å¾çš„å’Œ
        self.att = nn.Sequential(
            # 3Då·ç§¯å±‚ï¼škernel_size=(1,5,5) åªåœ¨ç©ºé—´ç»´åº¦å·ç§¯ï¼Œä¿æŒè§†å·®ç»´åº¦
            BasicConv(cv_chan, cv_chan, is_3d=True, bn=True, relu=True,
                     kernel_size=(1,5,5), padding=(0,2,2), stride=1, dilation=1),
            # 1x1x1å·ç§¯ï¼šè°ƒæ•´ç‰¹å¾ç»´åº¦
            nn.Conv3d(cv_chan, cv_chan, kernel_size=1, stride=1, padding=0, bias=False)
        )

        # ç‰¹å¾èšåˆç½‘ç»œï¼šè¿›ä¸€æ­¥å¤„ç†èåˆåçš„ç‰¹å¾
        self.agg = BasicConv(cv_chan, cv_chan, is_3d=True, bn=True, relu=True,
                            kernel_size=(1,5,5), padding=(0,2,2), stride=1, dilation=1)

        self.weight_init()

    def forward(self, cv, feat):
        """
        å‰å‘ä¼ æ’­ï¼Œå®ç°ä¸Šä¸‹æ–‡ä¸å‡ ä½•ä¿¡æ¯çš„èåˆ

        Args:
            cv: 3Dä»£ä»·ä½“å¼ é‡ [B, C, D, H, W]ï¼ŒDä¸ºè§†å·®ç»´åº¦
            feat: 2Då›¾åƒç‰¹å¾å¼ é‡ [B, C, H, W]

        Returns:
            Tensor: èåˆåçš„3Dç‰¹å¾å¼ é‡ [B, C, D, H, W]
        """
        # æ­¥éª¤1ï¼šè¯­ä¹‰ç‰¹å¾å¤„ç†
        # å°†2Dç‰¹å¾è½¬æ¢ä¸º3Dç‰¹å¾ (å¢åŠ è§†å·®ç»´åº¦)
        feat = self.semantic(feat).unsqueeze(2)  # [B, C, H, W] -> [B, C, 1, H, W]

        # æ­¥éª¤2ï¼šæ³¨æ„åŠ›æƒé‡è®¡ç®—
        # å°†è¯­ä¹‰ç‰¹å¾ä¸ä»£ä»·ä½“ç›¸åŠ ï¼Œé€šè¿‡æ³¨æ„åŠ›ç½‘ç»œç”Ÿæˆèåˆæƒé‡
        att = self.att(feat + cv)  # å¹¿æ’­æœºåˆ¶ï¼šfeatä¼šåœ¨è§†å·®ç»´åº¦æ‰©å±•

        # æ­¥éª¤3ï¼šç‰¹å¾èåˆ (é—¨æ§æœºåˆ¶)
        # ä½¿ç”¨sigmoidæ¿€æ´»çš„æ³¨æ„åŠ›æƒé‡ä½œä¸ºé—¨æ§ï¼Œæ§åˆ¶è¯­ä¹‰ç‰¹å¾çš„æ³¨å…¥ç¨‹åº¦
        cv = torch.sigmoid(att) * feat + cv  # æ®‹å·®è¿æ¥ + é—¨æ§èåˆ

        # æ­¥éª¤4ï¼šä¸Šä¸‹æ–‡èšåˆ
        # é€šè¿‡3Då·ç§¯è¿›ä¸€æ­¥èšåˆèåˆåçš„ç‰¹å¾ï¼Œå¢å¼ºè¡¨ç¤ºèƒ½åŠ›
        cv = self.agg(cv)

        return cv


class hourglass_fusion(nn.Module):
    """
    æ²™æ¼èåˆç½‘ç»œ - å¤šå°ºåº¦3Dä»£ä»·ä½“ä¼˜åŒ–æ¨¡å—

    è¯¥æ¨¡å—å®ç°äº†ä¸€ä¸ª3Dç¼–è§£ç å™¨ç»“æ„ï¼Œé€šè¿‡æ²™æ¼ç½‘ç»œä¼˜åŒ–ä»£ä»·ä½“ï¼š
    1. ç¼–ç è·¯å¾„ï¼šé€æ­¥ä¸‹é‡‡æ ·ï¼Œæå–ä¸åŒå°ºåº¦çš„ç‰¹å¾
       - Level 1: C -> 2C (1/2åˆ†è¾¨ç‡)
       - Level 2: 2C -> 4C (1/4åˆ†è¾¨ç‡)
       - Level 3: 4C -> 6C (1/8åˆ†è¾¨ç‡)
    2. ä¸Šä¸‹æ–‡èåˆï¼šåœ¨æ¯ä¸ªå°ºåº¦ä¸Šåº”ç”¨CGFæ¨¡å—ï¼Œæ³¨å…¥è¯­ä¹‰ä¿¡æ¯
    3. è§£ç è·¯å¾„ï¼šé€æ­¥ä¸Šé‡‡æ ·ï¼Œèåˆæµ…å±‚ç‰¹å¾
       - Level 3 -> Level 2: 6C -> 4C
       - Level 2 -> Level 1: 4C -> 2C
       - Level 1 -> Output: 2C -> 1 (è§†å·®æ¦‚ç‡åˆ†å¸ƒ)

    è®¾è®¡ç†å¿µï¼šé€šè¿‡å¤šå°ºåº¦å¤„ç†ï¼Œç½‘ç»œèƒ½å¤Ÿåœ¨ä¸åŒåˆ†è¾¨ç‡ä¸Šæ•æ‰åŒ¹é…ä¿¡æ¯ï¼Œ
    åŒæ—¶ç»“åˆè¯­ä¹‰ä¸Šä¸‹æ–‡æŒ‡å¯¼ï¼Œæå‡ä»£ä»·ä½“çš„è´¨é‡ã€‚
    """
    def __init__(self, in_channels):
        """
        åˆå§‹åŒ–æ²™æ¼èåˆç½‘ç»œ

        Args:
            in_channels: è¾“å…¥ä»£ä»·ä½“é€šé“æ•° (é€šå¸¸ä¸º8)
        """
        super(hourglass_fusion, self).__init__()

        self.conv1 = nn.Sequential(BasicConv(in_channels, in_channels*2, is_3d=True, bn=True, relu=True, kernel_size=3,
                                             padding=1, stride=2, dilation=1),
                                   BasicConv(in_channels*2, in_channels*2, is_3d=True, bn=True, relu=True, kernel_size=3,
                                             padding=1, stride=1, dilation=1))
                                    
        self.conv2 = nn.Sequential(BasicConv(in_channels*2, in_channels*4, is_3d=True, bn=True, relu=True, kernel_size=3,
                                             padding=1, stride=2, dilation=1),
                                   BasicConv(in_channels*4, in_channels*4, is_3d=True, bn=True, relu=True, kernel_size=3,
                                             padding=1, stride=1, dilation=1))                             

        self.conv3 = nn.Sequential(BasicConv(in_channels*4, in_channels*6, is_3d=True, bn=True, relu=True, kernel_size=3,
                                             padding=1, stride=2, dilation=1),
                                   BasicConv(in_channels*6, in_channels*6, is_3d=True, bn=True, relu=True, kernel_size=3,
                                             padding=1, stride=1, dilation=1)) 


        self.conv3_up = BasicConv(in_channels*6, in_channels*4, deconv=True, is_3d=True, bn=True,
                                  relu=True, kernel_size=(4, 4, 4), padding=(1, 1, 1), stride=(2, 2, 2))

        self.conv2_up = BasicConv(in_channels*4, in_channels*2, deconv=True, is_3d=True, bn=True,
                                  relu=True, kernel_size=(4, 4, 4), padding=(1, 1, 1), stride=(2, 2, 2))

        self.conv1_up = BasicConv(in_channels*2, 1, deconv=True, is_3d=True, bn=False,
                                  relu=False, kernel_size=(4, 4, 4), padding=(1, 1, 1), stride=(2, 2, 2))

        self.agg_0 = nn.Sequential(BasicConv(in_channels*8, in_channels*4, is_3d=True, kernel_size=1, padding=0, stride=1),
                                   BasicConv(in_channels*4, in_channels*4, is_3d=True, kernel_size=3, padding=1, stride=1),
                                   BasicConv(in_channels*4, in_channels*4, is_3d=True, kernel_size=3, padding=1, stride=1),)

        self.agg_1 = nn.Sequential(BasicConv(in_channels*4, in_channels*2, is_3d=True, kernel_size=1, padding=0, stride=1),
                                   BasicConv(in_channels*2, in_channels*2, is_3d=True, kernel_size=3, padding=1, stride=1),
                                   BasicConv(in_channels*2, in_channels*2, is_3d=True, kernel_size=3, padding=1, stride=1))


        self.CGF_32 = Context_Geometry_Fusion(in_channels*6, 160)
        self.CGF_16 = Context_Geometry_Fusion(in_channels*4, 192)
        self.CGF_8 = Context_Geometry_Fusion(in_channels*2, 64)

    def forward(self, x, imgs):
        """
        å‰å‘ä¼ æ’­ï¼Œå®ç°å¤šå°ºåº¦ä»£ä»·ä½“ä¼˜åŒ–

        Args:
            x: è¾“å…¥3Dä»£ä»·ä½“ [B, C, D, H, W]
            imgs: å¤šå°ºåº¦è¯­ä¹‰ç‰¹å¾åˆ—è¡¨ [x4, x8, x16, x32]

        Returns:
            Tensor: ä¼˜åŒ–åçš„è§†å·®æ¦‚ç‡åˆ†å¸ƒ [B, 1, D, H, W]
        """
        # === ç¼–ç é˜¶æ®µ ===
        conv1 = self.conv1(x)   # Level 1: [B, 2C, D/2, H/2, W/2]
        conv2 = self.conv2(conv1) # Level 2: [B, 4C, D/4, H/4, W/4]
        conv3 = self.conv3(conv2) # Level 3: [B, 6C, D/8, H/8, W/8]

        # === æœ€æ·±å±‚è¯­ä¹‰èåˆ ===
        conv3 = self.CGF_32(conv3, imgs[3])  # æ³¨å…¥1/32åˆ†è¾¨ç‡çš„è¯­ä¹‰ç‰¹å¾
        conv3_up = self.conv3_up(conv3)      # ä¸Šé‡‡æ ·åˆ°Level 2åˆ†è¾¨ç‡

        # === Level 2èåˆ ===
        # è·³è·ƒè¿æ¥ï¼šæ‹¼æ¥ä¸Šé‡‡æ ·ç‰¹å¾ä¸ç¼–ç ç‰¹å¾
        conv2 = torch.cat((conv3_up, conv2), dim=1)  # [B, 8C, D/4, H/4, W/4]
        conv2 = self.agg_0(conv2)                    # ç‰¹å¾èšåˆé™ç»´
        conv2 = self.CGF_16(conv2, imgs[2])          # æ³¨å…¥1/16åˆ†è¾¨ç‡çš„è¯­ä¹‰ç‰¹å¾
        conv2_up = self.conv2_up(conv2)              # ä¸Šé‡‡æ ·åˆ°Level 1åˆ†è¾¨ç‡

        # === Level 1èåˆ ===
        # è·³è·ƒè¿æ¥ï¼šæ‹¼æ¥ä¸Šé‡‡æ ·ç‰¹å¾ä¸ç¼–ç ç‰¹å¾
        conv1 = torch.cat((conv2_up, conv1), dim=1)  # [B, 4C, D/2, H/2, W/2]
        conv1 = self.agg_1(conv1)                    # ç‰¹å¾èšåˆé™ç»´
        conv1 = self.CGF_8(conv1, imgs[1])           # æ³¨å…¥1/8åˆ†è¾¨ç‡çš„è¯­ä¹‰ç‰¹å¾

        # === æœ€ç»ˆè¾“å‡º ===
        conv = self.conv1_up(conv1)  # ä¸Šé‡‡æ ·åˆ°åŸå§‹åˆ†è¾¨ç‡ï¼Œè¾“å‡ºå•é€šé“è§†å·®æ¦‚ç‡åˆ†å¸ƒ

        return conv


class CGI_Stereo(nn.Module):
    """
    CGI-Stereo ä¸»ç½‘ç»œç±»

    åŸºäºä¸Šä¸‹æ–‡ä¸å‡ ä½•äº¤äº’çš„ç«‹ä½“åŒ¹é…ç½‘ç»œï¼Œå®ç°ç«¯åˆ°ç«¯çš„è§†å·®ä¼°è®¡ï¼š

    æ ¸å¿ƒç»„ä»¶ï¼š
    1. ç‰¹å¾æå–ï¼šåŸºäº MobileNetV2 çš„å¤šå°ºåº¦ç‰¹å¾æå–
    2. ç‰¹å¾èåˆï¼šé€šè¿‡åå·ç§¯å®ç°å¤šå°ºåº¦ç‰¹å¾èåˆ
    3. ä»£ä»·ä½“æ„å»ºï¼šåŸºäºå½’ä¸€åŒ–ç›¸å…³æ€§çš„ç«‹ä½“åŒ¹é…
    4. ä¸Šä¸‹æ–‡èåˆï¼šCGF æ¨¡å—èåˆè¯­ä¹‰ä¸å‡ ä½•ä¿¡æ¯
    5. æ²™æ¼ä¼˜åŒ–ï¼š3D ç¼–è§£ç å™¨ä¼˜åŒ–ä»£ä»·ä½“
    6. ç©ºé—´é‡‘å­—å¡”ï¼šäºšåƒç´ çº§è§†å·®ç»†åŒ–
    7. è§†å·®å›å½’ï¼šTop-K åŠ æƒæ±‚å’Œçš„è½¯å›å½’

    ç½‘ç»œæµç¨‹ï¼š
    å·¦å³å›¾åƒ -> å¤šå°ºåº¦ç‰¹å¾æå– -> ç‰¹å¾èåˆ -> ç›¸å…³æ€§è®¡ç®— -> CGFèåˆ ->
    æ²™æ¼ä¼˜åŒ– -> è§†å·®å›å½’ -> äºšåƒç´ ç»†åŒ– -> é«˜åˆ†è¾¨ç‡è§†å·®å›¾
    """
    def __init__(self, maxdisp):
        """
        åˆå§‹åŒ– CGI-Stereo ç½‘ç»œ

        Args:
            maxdisp: æœ€å¤§è§†å·®å€¼ï¼Œé€šå¸¸ä¸º192æˆ–256
        """
        super(CGI_Stereo, self).__init__()
        self.maxdisp = maxdisp

        # === æ ¸å¿ƒæ¨¡å—åˆå§‹åŒ– ===
        self.feature = Feature()      # å¤šå°ºåº¦ç‰¹å¾æå–å™¨
        self.feature_up = FeatUp()    # ç‰¹å¾ä¸Šé‡‡æ ·èåˆæ¨¡å—
        chans = [16, 24, 32, 96, 160]  # MobileNetV2 å„å±‚é€šé“æ•°

        # === ç©ºé—´é‡‘å­—å¡”ç‰¹å¾æå– (Stem Networks) ===
        # stem_2: æå–1/2åˆ†è¾¨ç‡çš„ä½çº§ç‰¹å¾
        self.stem_2 = nn.Sequential(
            BasicConv(3, 32, kernel_size=3, stride=2, padding=1),  # [B,3,H,W] -> [B,32,H/2,W/2]
            nn.Conv2d(32, 32, 3, 1, 1, bias=False),
            nn.BatchNorm2d(32), nn.ReLU()
        )

        # stem_4: æå–1/4åˆ†è¾¨ç‡çš„ä¸­çº§ç‰¹å¾
        self.stem_4 = nn.Sequential(
            BasicConv(32, 48, kernel_size=3, stride=2, padding=1), # [B,32,H/2,W/2] -> [B,48,H/4,W/4]
            nn.Conv2d(48, 48, 3, 1, 1, bias=False),
            nn.BatchNorm2d(48), nn.ReLU()
        )

        self.spx = nn.Sequential(nn.ConvTranspose2d(2*32, 9, kernel_size=4, stride=2, padding=1),)
        self.spx_2 = Conv2x(32, 32, True)
        self.spx_4 = nn.Sequential(
            BasicConv(96, 32, kernel_size=3, stride=1, padding=1),
            nn.Conv2d(32, 32, 3, 1, 1, bias=False),
            nn.BatchNorm2d(32), nn.ReLU()
            )

        self.conv = BasicConv(96, 48, kernel_size=3, padding=1, stride=1)
        self.desc = nn.Conv2d(48, 48, kernel_size=1, padding=0, stride=1)
        self.semantic = nn.Sequential(
            BasicConv(96, 32, kernel_size=3, stride=1, padding=1),
            nn.Conv2d(32, 8, kernel_size=1, padding=0, stride=1, bias=False))
        self.agg = BasicConv(8, 8, is_3d=True, kernel_size=(1,5,5), padding=(0,2,2), stride=1)
        self.hourglass_fusion = hourglass_fusion(8)
        self.corr_stem = BasicConv(1, 8, is_3d=True, kernel_size=3, stride=1, padding=1)

    def forward(self, left, right):
        """
        å‰å‘ä¼ æ’­ï¼Œå®ç°å®Œæ•´çš„ç«‹ä½“åŒ¹é…æµç¨‹

        Args:
            left: å·¦å›¾åƒ [B, 3, H, W]
            right: å³å›¾åƒ [B, 3, H, W]

        Returns:
            List: è®­ç»ƒæ—¶è¿”å› [é«˜åˆ†è¾¨ç‡è§†å·®, ä½åˆ†è¾¨ç‡è§†å·®]ï¼Œæ¨ç†æ—¶è¿”å› [é«˜åˆ†è¾¨ç‡è§†å·®]
        """
        # === 1. å¤šå°ºåº¦ç‰¹å¾æå– ===
        # ä½¿ç”¨ MobileNetV2 æå–å·¦å³å›¾åƒçš„å¤šå°ºåº¦ç‰¹å¾
        features_left = self.feature(left)   # [x4, x8, x16, x32]
        features_right = self.feature(right) # [y4, y8, y16, y32]
        print(features_left[0].shape)
        print(features_right[0].shape)

        # ç‰¹å¾èåˆï¼šé€šè¿‡åå·ç§¯å®ç°å¤šå°ºåº¦ç‰¹å¾èåˆ
        features_left, features_right = self.feature_up(features_left, features_right)

        # === 2. ç©ºé—´é‡‘å­—å¡”ç‰¹å¾æå– ===
        # ä¸ºåç»­çš„ç©ºé—´é‡‘å­—å¡”æ¨¡å—æå–é¢å¤–çš„ä½çº§ç‰¹å¾
        stem_2x = self.stem_2(left)   # 1/2åˆ†è¾¨ç‡ç‰¹å¾ [B, 32, H/2, W/2]
        stem_4x = self.stem_4(stem_2x)  # 1/4åˆ†è¾¨ç‡ç‰¹å¾ [B, 48, H/4, W/4]
        stem_2y = self.stem_2(right)  # å³å›¾åƒ1/2åˆ†è¾¨ç‡ç‰¹å¾
        stem_4y = self.stem_4(stem_2y) # å³å›¾åƒ1/4åˆ†è¾¨ç‡ç‰¹å¾

        # === 3. ç‰¹å¾èåˆ ===
        # å°†stemç‰¹å¾ä¸MobileNetV2ç‰¹å¾åœ¨1/4åˆ†è¾¨ç‡å¤„èåˆ
        features_left[0] = torch.cat((features_left[0], stem_4x), 1)  # é€šé“æ•°: 48+48=96
        features_right[0] = torch.cat((features_right[0], stem_4y), 1)

        # === 4. åŒ¹é…ç‰¹å¾æå– ===
        # æå–ç”¨äºç«‹ä½“åŒ¹é…çš„æè¿°ç¬¦ç‰¹å¾
        match_left = self.desc(self.conv(features_left[0]))   # [B, 48, H/4, W/4]
        match_right = self.desc(self.conv(features_right[0])) # [B, 48, H/4, W/4]

        # === 5. ä»£ä»·ä½“æ„å»º ===
        # åŸºäºå½’ä¸€åŒ–ç›¸å…³æ€§æ„å»º3Dä»£ä»·ä½“
        corr_volume = build_norm_correlation_volume(match_left, match_right, self.maxdisp//4)  # [B, 1, D, H/4, W/4]
        corr_volume = self.corr_stem(corr_volume)  # åˆæ­¥å¤„ç†ä»£ä»·ä½“ [B, 8, D, H/4, W/4]

        # æå–è¯­ä¹‰ç‰¹å¾å¹¶æ‰©å±•åˆ°3Dç©ºé—´
        feat_volume = self.semantic(features_left[0]).unsqueeze(2)  # [B, 8, H/4, W/4] -> [B, 8, 1, H/4, W/4]
        # === 6. åˆå§‹ä»£ä»·ä½“æ„å»º ===
        # å°†è¯­ä¹‰ç‰¹å¾ä¸ç›¸å…³æ€§ä»£ä»·ä½“é€å…ƒç´ ç›¸ä¹˜ï¼Œå¢å¼ºåŒ¹é…ä½ç½®çš„å“åº”
        # ç„¶åé€šè¿‡3Då·ç§¯èšåˆå±€éƒ¨ä¸Šä¸‹æ–‡ä¿¡æ¯
        volume = self.agg(feat_volume * corr_volume)  # [B, 8, D, H/4, W/4]

        # === 7. æ²™æ¼ç½‘ç»œä¼˜åŒ– ===
        # é€šè¿‡3Dæ²™æ¼ç½‘ç»œè¿›ä¸€æ­¥ä¼˜åŒ–ä»£ä»·ä½“ï¼Œèåˆå¤šå°ºåº¦è¯­ä¹‰ä¿¡æ¯
        cost = self.hourglass_fusion(volume, features_left)  # [B, 1, D, H/4, W/4]

        # === 8. ç©ºé—´é‡‘å­—å¡”ç‰¹å¾æå– (ç”¨äºäºšåƒç´ ç»†åŒ–) ===
        # æå–é«˜åˆ†è¾¨ç‡ç©ºé—´ç‰¹å¾ï¼Œç”¨äºåç»­çš„äºšåƒç´ çº§è§†å·®ç»†åŒ–
        xspx = self.spx_4(features_left[0])  # å¤„ç†1/4åˆ†è¾¨ç‡ç‰¹å¾
        xspx = self.spx_2(xspx, stem_2x)     # èåˆ1/2åˆ†è¾¨ç‡ç‰¹å¾
        spx_pred = self.spx(xspx)            # ç”Ÿæˆ9é€šé“çš„ç©ºé—´åç§»é¢„æµ‹
        spx_pred = F.softmax(spx_pred, 1)    # è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ [B, 9, H, W]

        # === 9. è§†å·®å›å½’ (1/4åˆ†è¾¨ç‡) ===
        # ç”Ÿæˆè§†å·®å€™é€‰å€¼ (0 åˆ° maxdisp//4)
        disp_samples = torch.arange(0, self.maxdisp//4, dtype=cost.dtype, device=cost.device)
        disp_samples = disp_samples.view(1, self.maxdisp//4, 1, 1).repeat(
            cost.shape[0], 1, cost.shape[3], cost.shape[4])  # [B, D, H/4, W/4]

        # åŸºäºä»£ä»·ä½“è¿›è¡Œè½¯å›å½’ï¼šä½¿ç”¨Top-KåŠ æƒæ±‚å’Œ (K=2)
        # ç›¸æ¯”ä¼ ç»Ÿçš„argminï¼Œè¿™ç§æ–¹æ³•èƒ½äº§ç”Ÿæ›´å¹³æ»‘çš„è§†å·®å›¾
        pred = regression_soft(cost.squeeze(1), disp_samples, 2)  # [B, H/4, W/4]

        # === 10. äºšåƒç´ çº§ä¸Šä¸‹æ–‡ä¸Šé‡‡æ · ===
        # åˆ©ç”¨ç©ºé—´é‡‘å­—å¡”é¢„æµ‹çš„åç§»æƒé‡ï¼Œå®ç°äºšåƒç´ çº§è§†å·®ç»†åŒ–
        # å°†1/4åˆ†è¾¨ç‡çš„è§†å·®å›¾ä¸Šé‡‡æ ·åˆ°å…¨åˆ†è¾¨ç‡ï¼ŒåŒæ—¶ä¿æŒè¾¹ç¼˜ç»†èŠ‚
        pred_up = context_upsample(pred, spx_pred)  # [B, H, W]


        # === 11. è¾“å‡ºå¤„ç† ===
        if self.training:
            # è®­ç»ƒæ¨¡å¼ï¼šè¿”å›é«˜åˆ†è¾¨ç‡å’Œä½åˆ†è¾¨ç‡ä¸¤ä¸ªå°ºåº¦çš„è§†å·®å›¾
            # ç”¨äºå¤šå°ºåº¦ç›‘ç£æŸå¤±è®¡ç®—
            return [pred_up*4, pred.squeeze(1)*4]  # ä¹˜ä»¥4æ¢å¤åˆ°åŸå§‹è§†å·®å°ºåº¦
        else:
            # æ¨ç†æ¨¡å¼ï¼šåªè¿”å›é«˜åˆ†è¾¨ç‡è§†å·®å›¾
            return [pred_up*4]

"""
=== å…³é”®æŠ€æœ¯è§£æ ===

1. ä¸ºä»€ä¹ˆéœ€è¦ spx_pred (ç©ºé—´é‡‘å­—å¡”)ï¼Ÿ
ç›´æ¥ä¸Šé‡‡æ ·ä½åˆ†è¾¨ç‡è§†å·®å›¾ä¼šå¯¼è‡´è¾¹ç¼˜æ¨¡ç³Šå’Œç»†èŠ‚ä¸¢å¤±ã€‚
spx_pred é€šè¿‡å­¦ä¹ å±€éƒ¨åç§»æƒé‡ï¼Œå®ç°ç»†èŠ‚ä¿ç•™çš„äºšåƒç´ çº§ä¸Šé‡‡æ ·ï¼Œ
ç‰¹åˆ«åœ¨ç‰©ä½“è¾¹ç¼˜å’Œçº¹ç†åŒºåŸŸæ•ˆæœæ˜¾è‘—ã€‚

2. regression_topk çš„ä¼˜åŠ¿ï¼š
æ›¿ä»£ä¼ ç»Ÿçš„ argmin æ“ä½œï¼Œé€šè¿‡åŠ æƒæ’å€¼å¾—åˆ°æ›´å¹³æ»‘ã€æ›´å‡†ç¡®çš„è§†å·®å›¾ã€‚
Top-K (K=2) ç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è§†å·®æ¨¡ç³Šå’Œå™ªå£°ã€‚

3. maxdisp//4 çš„è®¾è®¡åŸç†ï¼š
- åœ¨1/4åˆ†è¾¨ç‡æ„å»ºä»£ä»·ä½“ï¼Œå‡å°‘è®¡ç®—é‡å’Œå†…å­˜å ç”¨
- è§†å·®æœç´¢èŒƒå›´ç›¸åº”ç¼©å°ä¸ºåŸæ¥çš„1/4
- æœ€ç»ˆç»“æœä¹˜ä»¥4æ¢å¤åˆ°åŸå§‹å°ºåº¦

4. CGI-Stereo çš„æ ¸å¿ƒåˆ›æ–°ï¼š
- Context-Geometry Fusionï¼šå°†è¯­ä¹‰ä¿¡æ¯ä¸å‡ ä½•çº¦æŸæœ‰æ•ˆèåˆ
- å¤šå°ºåº¦å¤„ç†ï¼šåœ¨ä¸åŒåˆ†è¾¨ç‡å±‚æ¬¡ä¸Šä¼˜åŒ–åŒ¹é…è´¨é‡
- äºšåƒç´ ç»†åŒ–ï¼šæ˜¾è‘—æå‡è§†å·®ä¼°è®¡çš„ç²¾åº¦

=== ç½‘ç»œä¼˜åŠ¿ ===
1. é«˜ç²¾åº¦ï¼šäºšåƒç´ çº§è§†å·®ä¼°è®¡ï¼Œè¾¾åˆ°äºšæ¯«ç±³çº§ç²¾åº¦
2. å¼ºé²æ£’æ€§ï¼šåœ¨å¼±çº¹ç†ã€é®æŒ¡åŒºåŸŸè¡¨ç°ä¼˜å¼‚
3. è®¡ç®—æ•ˆç‡ï¼šåˆç†çš„å¤æ‚åº¦ï¼Œé€‚åˆå®æ—¶åº”ç”¨
4. ç«¯åˆ°ç«¯è®­ç»ƒï¼šæ— éœ€å¤æ‚çš„åå¤„ç†
"""

# ================================================================================
# CGI-Stereo ç½‘ç»œæµ‹è¯•ä»£ç 
# ================================================================================

if __name__ == "__main__":
    import torch
    import time
    import numpy as np

    def print_separator(title):
        """æ‰“å°åˆ†éš”ç¬¦å’Œæ ‡é¢˜"""
        print("\n" + "="*60)
        print(f" {title}")
        print("="*60)

    def test_basic_functionality():
        """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
        print_separator("1. CGI-Stereo ç½‘ç»œåŸºæœ¬åŠŸèƒ½æµ‹è¯•")

        # è®¾å¤‡é€‰æ‹©
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")

        # åˆ›å»ºç½‘ç»œ
        maxdisp = 192
        model = CGI_Stereo(maxdisp=maxdisp).to(device)
        print(f"âœ“ ç½‘ç»œåˆ›å»ºæˆåŠŸï¼Œæœ€å¤§è§†å·®: {maxdisp}")

        # æµ‹è¯•è¾“å…¥å°ºå¯¸
        batch_size = 1
        height, width = 384, 640  # å¸¸ç”¨çš„è¾“å…¥å°ºå¯¸
        left = torch.randn(batch_size, 3, height, width).to(device)
        right = torch.randn(batch_size, 3, height, width).to(device)

        print(f"è¾“å…¥å°ºå¯¸: {left.shape}")

        # è®¾ç½®è®­ç»ƒæ¨¡å¼
        model.train()
        start_time = time.time()
        with torch.no_grad():
            outputs_train = model(left, right)
        train_time = time.time() - start_time

        print(f"âœ“ è®­ç»ƒæ¨¡å¼æµ‹è¯•æˆåŠŸ")
        print(f"  - è¾“å‡ºæ•°é‡: {len(outputs_train)}")
        print(f"  - é«˜åˆ†è¾¨ç‡è§†å·®å›¾: {outputs_train[0].shape}")
        print(f"  - ä½åˆ†è¾¨ç‡è§†å·®å›¾: {outputs_train[1].shape}")
        print(f"  - æ¨ç†æ—¶é—´: {train_time:.4f}s")

        # è®¾ç½®æ¨ç†æ¨¡å¼
        model.eval()
        start_time = time.time()
        with torch.no_grad():
            outputs_infer = model(left, right)
        infer_time = time.time() - start_time

        print(f"âœ“ æ¨ç†æ¨¡å¼æµ‹è¯•æˆåŠŸ")
        print(f"  - è¾“å‡ºæ•°é‡: {len(outputs_infer)}")
        print(f"  - è§†å·®å›¾: {outputs_infer[0].shape}")
        print(f"  - æ¨ç†æ—¶é—´: {infer_time:.4f}s")

        return model, left, right

    def test_different_input_sizes():
        """æµ‹è¯•ä¸åŒè¾“å…¥å°ºå¯¸"""
        print_separator("2. ä¸åŒè¾“å…¥å°ºå¯¸æµ‹è¯•")

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = CGI_Stereo(maxdisp=192).to(device)
        model.eval()

        test_sizes = [
            (256, 512),   # å°å°ºå¯¸
            (384, 640),   # ä¸­ç­‰å°ºå¯¸ (å¸¸ç”¨)
            (480, 640),   # KITTI å°ºå¯¸
            (512, 960),   # å¤§å°ºå¯¸
        ]

        for h, w in test_sizes:
            try:
                left = torch.randn(1, 3, h, w).to(device)
                right = torch.randn(1, 3, h, w).to(device)

                with torch.no_grad():
                    start_time = time.time()
                    outputs = model(left, right)
                    end_time = time.time()

                print(f"âœ“ å°ºå¯¸ {h}x{w}: è¾“å‡º {outputs[0].shape}, ç”¨æ—¶ {end_time-start_time:.4f}s")

            except Exception as e:
                print(f"âœ— å°ºå¯¸ {h}x{w}: å¤±è´¥ - {e}")

    def test_gradient_flow():
        """æµ‹è¯•æ¢¯åº¦æµ"""
        print_separator("3. æ¢¯åº¦æµæµ‹è¯•")

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = CGI_Stereo(maxdisp=192).to(device)
        model.train()

        # åˆ›å»ºéœ€è¦æ¢¯åº¦çš„è¾“å…¥ï¼ˆå…ˆåœ¨CPUåˆ›å»ºç„¶åç§»åŠ¨åˆ°GPUï¼Œç¡®ä¿æ˜¯å¶å­å¼ é‡ï¼‰
        left = torch.randn(1, 3, 384, 640, requires_grad=True)
        right = torch.randn(1, 3, 384, 640, requires_grad=True)
        left = left.to(device)
        right = right.to(device)

        # å‰å‘ä¼ æ’­
        outputs = model(left, right)

        # åˆ›å»ºè™šæ‹ŸæŸå¤±
        loss = sum(torch.mean(output) for output in outputs)

        # åå‘ä¼ æ’­
        loss.backward()

        # æ£€æŸ¥è¾“å…¥æ¢¯åº¦
        left_grad_norm = left.grad.norm().item() if left.grad is not None else 0.0
        right_grad_norm = right.grad.norm().item() if right.grad is not None else 0.0

        # æ£€æŸ¥æ¨¡å‹å‚æ•°æ¢¯åº¦
        param_grads = []
        total_grad_norm = 0.0
        for name, param in model.named_parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                param_grads.append((name, grad_norm))
                total_grad_norm += grad_norm

        print(f"âœ“ æ¢¯åº¦æµæµ‹è¯•æˆåŠŸ")
        print(f"  - è¾“å…¥æ¢¯åº¦èŒƒæ•°: å·¦={left_grad_norm:.6f}, å³={right_grad_norm:.6f}")
        print(f"  - å‚æ•°æ¢¯åº¦æ•°é‡: {len(param_grads)}/{len(list(model.named_parameters()))}")
        print(f"  - æ€»æ¢¯åº¦èŒƒæ•°: {total_grad_norm:.6f}")

        # æ˜¾ç¤ºå‰5ä¸ªå‚æ•°çš„æ¢¯åº¦èŒƒæ•°
        for name, grad_norm in param_grads[:5]:
            print(f"    {name}: {grad_norm:.6f}")

        # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦ä¸º0
        zero_grad_count = sum(1 for _, grad_norm in param_grads if grad_norm < 1e-8)
        if zero_grad_count > 0:
            print(f"  - âš ï¸ è­¦å‘Š: {zero_grad_count} ä¸ªå‚æ•°æ¢¯åº¦æ¥è¿‘0")
        else:
            print("  - âœ“ æ‰€æœ‰å‚æ•°æ¢¯åº¦æ­£å¸¸")

    def test_memory_usage():
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        print_separator("4. å†…å­˜ä½¿ç”¨æµ‹è¯•")

        if not torch.cuda.is_available():
            print("CUDA ä¸å¯ç”¨ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
            return

        device = torch.device('cuda')

        # æ¸…ç†GPUå†…å­˜
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()

        initial_memory = torch.cuda.memory_allocated() / 1024**3  # GB
        peak_initial = torch.cuda.max_memory_allocated() / 1024**3  # GB

        model = CGI_Stereo(maxdisp=192).to(device)
        model_memory = torch.cuda.memory_allocated() / 1024**3  # GB

        # æµ‹è¯•æ¨ç†
        model.eval()
        batch_sizes = [1, 2, 4]

        for batch_size in batch_sizes:
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()

            left = torch.randn(batch_size, 3, 384, 640).to(device)
            right = torch.randn(batch_size, 3, 384, 640).to(device)

            input_memory = torch.cuda.memory_allocated() / 1024**3  # GB

            with torch.no_grad():
                outputs = model(left, right)

            peak_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB

            print(f"âœ“ Batch Size {batch_size}:")
            print(f"  - æ¨¡å‹å‚æ•°: {model_memory:.3f} GB")
            print(f"  - è¾“å…¥æ•°æ®: {input_memory - model_memory:.3f} GB")
            print(f"  - å³°å€¼å†…å­˜: {peak_memory:.3f} GB")
            print(f"  - æ€»å†…å­˜å¢é•¿: {peak_memory - initial_memory:.3f} GB")

            del left, right, outputs

    def test_output_properties():
        """æµ‹è¯•è¾“å‡ºå±æ€§"""
        print_separator("5. è¾“å‡ºå±æ€§æµ‹è¯•")

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = CGI_Stereo(maxdisp=192).to(device)
        model.eval()

        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        left = torch.randn(1, 3, 384, 640).to(device)
        right = torch.randn(1, 3, 384, 640).to(device)

        with torch.no_grad():
            outputs = model(left, right)
            pred_disp = outputs[0]

        print(f"è¾“å‡ºç»Ÿè®¡ä¿¡æ¯:")
        print(f"  - å½¢çŠ¶: {pred_disp.shape}")
        print(f"  - æ•°æ®ç±»å‹: {pred_disp.dtype}")
        print(f"  - è®¾å¤‡: {pred_disp.device}")
        print(f"  - æœ€å°å€¼: {pred_disp.min().item():.3f}")
        print(f"  - æœ€å¤§å€¼: {pred_disp.max().item():.3f}")
        print(f"  - å¹³å‡å€¼: {pred_disp.mean().item():.3f}")
        print(f"  - æ ‡å‡†å·®: {pred_disp.std().item():.3f}")

        # æ£€æŸ¥è§†å·®èŒƒå›´æ˜¯å¦åˆç†
        max_possible_disp = 192  # è®¾ç½®çš„æœ€å¤§è§†å·®
        actual_max = pred_disp.max().item()

        if 0 <= actual_max <= max_possible_disp * 1.1:  # å…è®¸10%çš„è¯¯å·®
            print(f"âœ“ è§†å·®èŒƒå›´åˆç†: 0 <= {actual_max:.3f} <= {max_possible_disp}")
        else:
            print(f"âš  è§†å·®èŒƒå›´å¯èƒ½å¼‚å¸¸: {actual_max:.3f}")

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ— æ•ˆå€¼
        if torch.isfinite(pred_disp).all():
            print("âœ“ è¾“å‡ºå€¼éƒ½æ˜¯æœ‰é™æ•°")
        else:
            print("âœ— è¾“å‡ºä¸­å­˜åœ¨æ— é™å€¼æˆ–NaN")



    def run_performance_benchmark():
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print_separator("7. æ€§èƒ½åŸºå‡†æµ‹è¯•")

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = CGI_Stereo(maxdisp=192).to(device)
        model.eval()

        # é¢„çƒ­
        left = torch.randn(1, 3, 384, 640).to(device)
        right = torch.randn(1, 3, 384, 640).to(device)

        for _ in range(5):
            with torch.no_grad():
                _ = model(left, right)

        # æ€§èƒ½æµ‹è¯•
        num_runs = 20
        times = []

        print(f"è¿è¡Œ {num_runs} æ¬¡æ¨ç†æµ‹è¯•...")

        with torch.no_grad():
            for i in range(num_runs):
                start_time = time.time()
                outputs = model(left, right)
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                end_time = time.time()
                times.append(end_time - start_time)

                if (i + 1) % 5 == 0:
                    print(f"  å®Œæˆ {i+1}/{num_runs}")

        avg_time = np.mean(times)
        std_time = np.std(times)
        min_time = np.min(times)
        max_time = np.max(times)
        fps = 1.0 / avg_time

        print(f"âœ“ æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"  - å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.4f} Â± {std_time:.4f}s")
        print(f"  - æœ€å¿«æ—¶é—´: {min_time:.4f}s")
        print(f"  - æœ€æ…¢æ—¶é—´: {max_time:.4f}s")
        print(f"  - ç†è®ºFPS: {fps:.2f}")

        # è®¡ç®—FLOPs (å¦‚æœå®‰è£…äº†fvcore)
        try:
            from fvcore.nn import FlopCountAnalysis
            model_flops = FlopCountAnalysis(model, (left, right))
            total_flops = model_flops.total()
            print(f"  - æ€»è®¡ç®—é‡: {total_flops/1e9:.2f} GFLOPs")
        except ImportError:
            print("  - æœªå®‰è£… fvcoreï¼Œè·³è¿‡ FLOPs è®¡ç®—")

    def main():
        """ä¸»æµ‹è¯•å‡½æ•°"""
        print("ğŸš€ CGI-Stereo ç½‘ç»œæµ‹è¯•å¼€å§‹")
        print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
        print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"GPU: {torch.cuda.get_device_name()}")

        try:
            # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
            model, left, right = test_basic_functionality()

            # ä¸åŒè¾“å…¥å°ºå¯¸æµ‹è¯•
            test_different_input_sizes()

            # æ¢¯åº¦æµæµ‹è¯•
            test_gradient_flow()

            # å†…å­˜ä½¿ç”¨æµ‹è¯•
            test_memory_usage()

            # è¾“å‡ºå±æ€§æµ‹è¯•
            test_output_properties()

            # æ€§èƒ½åŸºå‡†æµ‹è¯•
            run_performance_benchmark()

            print_separator("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
            print("CGI-Stereo ç½‘ç»œè¿è¡Œæ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒæˆ–æ¨ç†ã€‚")

        except Exception as e:
            print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"é”™è¯¯ä¿¡æ¯: {e}")
            import traceback
            traceback.print_exc()

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    main()